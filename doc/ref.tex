%% Copyright 2010 Peter K. Keller (psilord@cs.wisc.edu)
%% 
%% Licensed under the Apache License, Version 2.0 (the "License"); you
%% may not use this file except in compliance with the License. You may
%% obtain a copy of the License at
%% 
%% \indent http://www.apache.org/licenses/LICENSE-2.0
%% 
%% Unless required by applicable law or agreed to in writing, software
%% distributed under the License is distributed on an "AS IS" BASIS,
%% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
%% or implied. See the License for the specific language governing
%% permissions and limitations under the License.


\documentclass[titlepage,12pt]{book}

\usepackage{tipa}			% for \textpipe 
\usepackage{textcomp}		% for \textdegree
\usepackage{listings}		% for the lisp/barelisp environment
\usepackage{microtype}		% To make things slightly more pretty
\usepackage{xspace}			% a life saver
%\usepackage[T1]{fontenc}	% make underscores show up nice. Bad with pdflatex.
\usepackage{html}			% For Latex2html

\usepackage{hyperref}		% For PDF generation MUST BE LAST
\usepackage[all]{hypcap}	% Except for this, if I'm using hyperref
							% Useful to link against figures and captions at
							% the top of the figure/caption instead of the
							% bottom.
\hypersetup{
	linktocpage,
	citecolor=black,
	filecolor=black,
	linkcolor=blue,
	urlcolor=black,
	colorlinks=true
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Various macros
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%
% Latexery
%%%%%%%%%
\newcommand{\phlabel}[1]{\phantomsection\label{#1}}

%%%%%%%%%
% Sigh. Font alterations for latex versus web pages...
% First arguments means what'll be in the latex, second means what'll be in
% the latex2html.
%%%%%%%%%
\newcommand{\xfootnotesize}{\latexhtml{\footnotesize}{}}
\newcommand{\xsmall}{\latexhtml{\small}{}}
\newcommand{\xnormalsize}{\latexhtml{\normalsize}{}}

%%%%%%%%%
% abbreviations, yay xspace!
%%%%%%%%%
\newcommand{\sbcl}{SBCL\xspace}
\newcommand{\mw}{Master-Slave\xspace}
\newcommand{\clmw}{\xsmall\textsc{CL-MW}\xnormalsize\xspace}
\newcommand{\package}[1]{\mbox{:\uppercase{\xsmall\texttt{#1}\xnormalsize}} package\xspace}
\newcommand{\mwpackage}{\package{CL-MW}}
\newcommand{\sa}{\textit{slave algorithm}\xspace}
\newcommand{\ma}{\textit{master algorithm}\xspace}
\newcommand{\ta}{\textit{task algorithm}\xspace}
\newcommand{\Ta}{\textit{Task algorithm}\xspace}
\newcommand{\sas}{\textit{slave algorithm}s\xspace}
\newcommand{\Sas}{\textit{Slave algorithm}s\xspace}
\newcommand{\mas}{\textit{master algorithm}s\xspace}
\newcommand{\Mas}{\textit{Master algorithm}s\xspace}
\newcommand{\tas}{\textit{task algorithm}s\xspace}
\newcommand{\Tas}{\textit{Task algorithm}s\xspace}
\newcommand{\tp}{\textit{task policy}\xspace}
\newcommand{\Tp}{\textit{Task policy}\xspace}
\newcommand{\Tps}{\textit{Task policies}\xspace}
\newcommand{\rfile}{\textit{resource file}\xspace}
\newcommand{\un}{\texttt{:unordered}\xspace}
\newcommand{\inter}{\texttt{:intermingle}\xspace}
\newcommand{\ord}{\texttt{:ordered}\xspace}
\newcommand{\tag}{\texttt{:tag}\xspace}

%%%%%%%%%
%%The usual suspects
%%%%%%%%%
\newcommand{\dash}{\texttt{-}}

%\newcommand{\func}[1]{\xsmall\mbox{\uppercase{\texttt{#1}}}\xnormalsize\xspace}
%\newcommand{\macro}[1]{\xsmall\mbox{\uppercase{\texttt{#1}}}\xnormalsize\xspace}
%\newcommand{\genmacro}[2]{\xsmall\mbox{\uppercase{\texttt{#1\textit{#2}}}}\xnormalsize\xspace}
%\newcommand{\genmacroname}[1]{\small\mbox{\uppercase{\texttt{#1\textit{name}}}}\normalsize\xspace}

\newcommand{\func}[1]{\mbox{\texttt{#1}}\xspace}
\newcommand{\macro}[1]{\mbox{\texttt{#1}}\xspace}
\newcommand{\sym}[1]{\mbox{\texttt{#1}}\xspace}
\newcommand{\genmacro}[2]{\mbox{\texttt{#1\textit{#2}}}\xspace}
\newcommand{\genmacroname}[1]{\mbox{\texttt{#1\textit{name}}}\xspace}

\newcommand{\syscall}[1]{\mbox{\texttt{#1()}}\xspace}
\newcommand{\file}[1]{\texttt{#1}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}\xspace}
\newcommand{\exec}[1]{\texttt{#1}\xspace}
\newcommand{\bool}[1]{\texttt{#1}\xspace}
\newcommand{\bold}[1]{\textbf{#1}\xspace}
\newcommand{\opt}[1]{\texttt{#1}\xspace}
\newcommand{\val}[1]{\textit{#1}\xspace}
\newcommand{\var}[1]{\texttt{#1}\xspace}
\newcommand{\EnvVar}[1]{\texttt{#1}\xspace}
\newcommand{\Option}[1]{\dash\dash\texttt{#1}}
\newcommand{\OptionV}[2]{\dash\dash\texttt{#1} \textit{#2}}
\newcommand{\key}{\texttt{\&key}\xspace}
\newcommand{\rest}{\texttt{\&rest}\xspace}
\newcommand{\optional}{\texttt{\&optional}\xspace}
\newcommand{\keyword}[1]{\texttt{:#1}\xspace}

%%%%%%%%%
% Meta-commentary
%%%%%%%%%
\newcommand{\Todo}{\begin{center}\fbox{\textbf{TODO}}\end{center}}
\newcommand{\Note}{\texttt{\underline{Note}:}\xspace}
\newcommand{\Warn}{\texttt{\underline{Warning}:}\xspace}
\newcommand{\Important}{\texttt{\underline{Important}:}\xspace}
\newcommand{\Limitation}{\texttt{\underline{Limitation}:}\xspace}

%%%%%%%%%
% The API list layout in the technical section
%%%%%%%%%
\newcommand{\apiheader}[1]{\begin{center}\underline{#1}\end{center}}
\newcommand{\apifunc}[2]{\noindent\xsmall\texttt{(#1)}\hspace*{\fill}\xnormalsize\texttt{#2}}
\newenvironment{apientry}[2]
	{\apifunc{#1}{#2}\begin{quotation}}
	{\end{quotation}}
\newenvironment{explainline}[1]
	{\noindent\texttt{#1}\begin{quotation}}
	{\end{quotation}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Environments
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%
% A pile of lisp just bare in the code with no annotations or labels.
%%%%%%%%%

\lstnewenvironment{barelisp}[1][]
{\lstset{
language=Lisp,
% the size of the fonts that are used for the code
basicstyle=\small,
keywordstyle=\ttfamily,
identifierstyle=\ttfamily,
commentstyle=\ttfamily,
stringstyle=\ttfamily,
% where to put the line-numbers
%numbers=left,
% the step between two line-numbers. If it's 1 each line will be numbered
%stepnumber=2,
% how far the line-numbers are from the code
%numbersep=5pt,
% show spaces adding particular underscores
showspaces=false,
% underline spaces within strings
showstringspaces=false,
% show tabs within strings adding particular underscores
showtabs=false,
% put various lines around the code
%frame=tb,
% sets default tabsize to 2 spaces
tabsize=2,
% sets the caption-position to bottom
captionpos=b,
% subtract the amount of space used for the caption since I don't have one.
belowskip=-12pt,
% sets automatic line breaking
breaklines=true,
% sets if automatic breaks should only happen at whitespace
breakatwhitespace=true,
% show the filename of files included with \lstinputlisting; also 
% try caption instead of title
title=\lstname,
% if you want to add more keywords to the set
%morekeywords={*,...},
% Follow the chapter numbers
numberbychapter=true,
#1
}}
{}

%%%%%%%%%
% A pile of lisp in the code with a box around it and a caption
%%%%%%%%%
\lstnewenvironment{lisp}[1][]
{\lstset{
language=Lisp,
% the size of the fonts that are used for the code
basicstyle=\small,
keywordstyle=\ttfamily,
identifierstyle=\ttfamily,
commentstyle=\ttfamily,
stringstyle=\ttfamily,
% where to put the line-numbers
%numbers=left,
% the step between two line-numbers. If it's 1 each line will be numbered
%stepnumber=2,
% how far the line-numbers are from the code
%numbersep=5pt,
% show spaces adding particular underscores
showspaces=false,
% underline spaces within strings
showstringspaces=false,
% show tabs within strings adding particular underscores
showtabs=false,
% put various lines around the code
frame=tblr,
% sets default tabsize to 2 spaces
tabsize=2,
% sets the caption-position to bottom
captionpos=t,
% sets automatic line breaking
breaklines=true,
% sets if automatic breaks should only happen at whitespace
breakatwhitespace=true,
% show the filename of files included with \lstinputlisting; also 
% try caption instead of title
title=\lstname,
% if you want to add more keywords to the set
%morekeywords={*,...},
% Follow the chapter numbers
numberbychapter=true,
#1
}}
{}

%%%%%%%%%
% A version history entry in the appendix.
%%%%%%%%%
\newenvironment{verhist}[2]
	{\noindent\textbf{Version #1}\\\indent\xsmall(Released #2)\xnormalsize\begin{itemize}}
	{\end{itemize}}
\newcommand{\removed}{\item \bold{Removed:}\xspace}
\newcommand{\obsolete}{\item \bold{Obsolete:}\xspace}
\newcommand{\deprecate}{\item \bold{Deprecated:}\xspace}
\newcommand{\info}{\item \bold{Info:}\xspace}
\newcommand{\newfeature}{\item \bold{NewFeature:}\xspace}
\newcommand{\changed}{\item \bold{Changed:}\xspace}
\newcommand{\bugfix}{\item \bold{BugFix:}\xspace}
\newcommand{\knownbug}{\item \bold{KnownBug:}\xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Misc.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hyphenation{de-struct-ur-ing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The beginning of the document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\frontmatter 

\title{\textbf{CL-MW}\\
\normalsize A Master-Slave Library for Distributed\\
Programming in Common Lisp\\
Version 0.3}
\author{Peter Keller\\psilord@cs.wisc.edu}
\date{\today}
\maketitle
\newpage
\tableofcontents
\newpage

\chapter{License}

The source code to \clmw, the example programs, and the
documentation source and contents are under the Apache 2 license:

\begin{center}
\framebox[5.1in][l]{
\begin{minipage}[t]{4.9in}
Copyright 2010-2012 Peter K. Keller (psilord@cs.wisc.edu)\\

Licensed under the Apache License, Version 2.0 (the ``License"); you
may not use this file except in compliance with the License. You may
obtain a copy of the License at

\begin{center}
\url{http://www.apache.org/licenses/LICENSE-2.0}
\end{center}

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ``AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
or implied. See the License for the specific language governing
permissions and limitations under the License.
\end{minipage}
}
\end{center}


\mainmatter

\chapter{Overview}

\section{Background}
\mw is a distributed computing paradigm where a master process
partitions work to one or more slave processes, collects the results,
and produces the required end solution from those partial results.
The work is usually of a fine to medium grained nature. The work
request, called a task, and the slave's response, called a result,
do not individually require large amounts of disk space, memory space,
or network resources.  The tasks may be ordered or unordered. Ordered
tasks must be assigned to a slave which may additionally hold
persistent information.  Unordered tasks run on any available slave and
are often the only kind of tasks supported by \mw systems.  Examples of
problems applicable to the \mw paradigm are: numerical optimization,
exploring game search trees, web-crawling, and Monte-Carlo simulations.

In many \mw execution environments, it is an unavoidable reality that
execute nodes asynchronously connect and unexpectedly disconnect from
the computation.  This is called slave churn. Many \mw systems accept
this reality and provide task scheduling algorithms such that when
a slave disconnects, times out, or otherwise is deemed unusable,
tasks assigned to that slave are recycled back into the task pool
to be distributed out to a different slave at a later time. If the
master process exits prematurely, then the slaves all die as soon as
they notice, as to not consume computing resources.

\mw systems may be coupled with an external batch scheduling
system. The batch system can manage resource acquisitions for the
slave processes and provide an environment to restart the computation
in the face of machine or other environmental failure.

\section{\clmw}
\clmw is a \mw implementation written in, and for, Common Lisp. The
design of the library's API was designed for ease of use and rapid
prototyping of \mw applications.  The library decouples management
of the task/result flow through the slaves from the act of spawning
slaves to simplify interaction with pre-existing batch systems. \clmw
has three main parts to be specified by the application author: one
or more \tas, a \ma, and optionally a \sa. \clmw implements a single
binary executable containing both the master and slave code.

The \ma produces tasks and inserts them into \clmw.  Tasks are data
packets destined for a specific \ta (and potentially a specific slave
as well) and which are stored in the master process.  \Tas are pieces
of code in the slave which process the tasks into results which
are sent back to the master process for consumption by the \ma.
\clmw maintains a pool of tasks running and waiting to be run.
While all of the tasks can be created during the \ma initialization,
tasks can also be added dynamically.  Tasks may be dynamically added
based on results from earlier tasks, or they may be dynamically added
to limit memory used to store them.  Tasks have meta-data associated
with them that can dictate where or in what manner the task should
be processed. This is known as a \tp.

An optional \sa allows arbitrary computation to happen in the slave
in between processing one or more task. An example of such a slave
computation is downloading a database upon slave startup which is
used by the \tas and then removing it when the slave shuts down.

\subsection{Task Algorithms}

A \ta is a piece of code written by the application author
which converts tasks into results in the slave.  The macro
\macro{define-mw-algorithm} defines a \ta. The parameter list of
this macro is similar to \macro{defun}. You specify a name and a
lambda list. The lambda list keywords: \key, \rest, and \optional are
supported, but only in a basic manner. Only one lambda list keyword
may be used at a time in a lambda list. Supplied-p-parameters are
not supported.  The \ta body cannot return a set of values with
\func{values}. There must only be one value that is returned.
These limitations will be removed in future versions of \clmw.

Here is an example definition of a \ta which echos back its argument
unchanged. \Note The arguments accepted and the result returned
are that which you would have done had the \ta been defined with
\macro{defun}.

\begin{lisp}[caption=The \texttt{echo} Task Algorithm]
(define-mw-algorithm echo (val)
	val)
\end{lisp}

The result of expanding \macro{define-mw-algorithm} is a collection of
functions and a macro as defined in table~\ref{expanded-define-mw-algorithm}.

\begin{table}[hbt]
\begin{center}
\begin{tabular}{||l|l||} \hline
\bold{Symbol}							& \bold{Kind} \\ \hline
\func{echo}								& Function \\ \hline
\macro{mw-funcall-echo}					& Macro \\ \hline
\macro{mw-with-task-policy-for-echo}	& Macro \\ \hline
\func{mw-set-target-number-for-echo}	& Function \\ \hline
\func{mw-get-target-number-for-echo}	& Function \\ \hline
\func{mw-pending-tasks-for-echo}		& Function \\ \hline
\func{mw-upto-target-number-echo}		& Function \\ \hline
\end{tabular}
\caption{\label{expanded-define-mw-algorithm}
		Expansion of \macro{define-mw-algorithm} for the \texttt{echo} \ta.}
\end{center}
\end{table}

The functions and macro created in expansion of the \emph{echo} \ta are
grouped into three sets: the \emph{echo} function itself--which is the
body of the \macro{define-mw-algorithm} macro, the task creation macros
\macro{mw-funcall-echo} and \macro{mw-with-task-policy-for-echo},
and a set of functions which allow one to manage how many pending
tasks for this \ta are queued.

\subsubsection{The \macro{mw-funcall-echo} Macro}

The macro \macro{mw-funcall-echo} creates a new task and separates
the arguments to the \textit{echo} function--ultimately called with
those arguments in the slave process, from the \tp associated with
the task.

The signature of \macro{mw-funcall-echo} is:

\begin{barelisp}
(mw-funcall-echo (str) 
                 (&key sid tag do-it-anyway (retry t)))
\end{barelisp}

This example call of \macro{mw-funcall-echo} shows the creation of a
new \textit{echo} task with an argument of \texttt{"Hello World"}.
All task arguments to the \ta must occur within the first set of
parentheses and in the order specified for the specific {\ta}'s
parameter list.  Processing this task will result in a result
structure given back to the \ma which contains the echoed string
\texttt{"Hello World"}.

\begin{barelisp}
(mw-funcall-echo ("Hello World"))
\end{barelisp}

\subsubsection{Task Policy}

The \tp associated with a task describes \emph{how} and \emph{where}
a task should be executed.  The \tp for a task is defined when a
task is created via the \macro{my-funcall-*} macro. Part of the
default \tp for a task to be considered unordered and to run on
any available slave.  Another part of the default is that if the
task running on an arbitrary slave---which then disconnects without
providing an answer, the task is reassigned to a different slave for
processing and this can happen many times.  The full default \tp is
specified on page ~\pageref{task-policy} as well as what each portion
of the policy means.

Through the \tp, one may assign tasks to run on previously acquired
ordered slaves. These ordered tasks will be run in the
order inserted by the \ma.  The \tp is directly responsible for a
ordered task possibly becoming \emph{unrunnable}. This happens when
the ordered slave which is processing the task disconnects. The
default \tp for ordered tasks is that any tasks being processed on
the disconnected slave \textit{or queued waiting to run on the slave}
become unrunnable and the task structures are given back to the \ma.

This example call of \macro{mw-funcall-echo} is the same as above with
respect to the task generated and the result expected. However, when
the result structure associated with this task is presented to the
\ma, the result will have in it the associated tag of \texttt{1234}.
The tag of a task may be any Lisp form.

\begin{barelisp}
(mw-funcall-echo ("Hello World") :tag 1234)
\end{barelisp}

\subsubsection{The \macro{mw-with-task-policy-for-echo} Macro}

This destructuring macro creates a lexical environment for its body in
which a function is bound that will submit tasks into \clmw for the \ta
with the specified \tp.  If no \tp keywords are used, then the default
values are chosen as specified on page ~\pageref{task-policy}. This
allows mapping a task creation function across a list or using it in
other higher order contexts.

This example creates a function called \emph{add-echo-task} which
will add tasks for the \emph{echo} \ta. Each added task follows the
default \tp.

\begin{barelisp}
(mw-with-task-policy-for-echo (add-echo-task)
  (mapc #'add-echo-task '("one" "two" "three")))
\end{barelisp}

This next example creates a function which will add tasks for the
\emph{echo} \ta that do not required to be retried if they fail to
be executed.

\begin{barelisp}
(mw-with-task-policy-for-echo (add-echo-task :retry nil)
  (mapc #'add-echo-task '("one" "two" "three")))
\end{barelisp}

\subsubsection{Task Algorithm Target Numbers}

Target numbers are values recorded by \clmw and set by the \ma which
represent the number of pending to run tasks for a \ta that should be
kept in memory at all times.  It is useful when a task generator in the
\ma can produce many more tasks than can fit into the master process's
memory or disk on the resource where the master process is running.

An analogy to the \clmw concept of target numbers is the temperature
setting of a thermostat. If one sets a thermostat to 70{\textdegree}F
then when the temperature falls below that, the furnace kicks in
and injects heat into the room until the target number is reached.
As the furnace heats up the room it may overheat it, but it generally
shouldn't since the goal is to keep the temperature stable at the
thermostat's setting.

In the same manner as the furnace, the \ma can use the target number
for a \ta to create the required number of tasks (which could be
zero if no new tasks are needed) into \clmw until the target number
is reached. The \ma can run millions or billions of tasks through
without having to have all of them in existence at once. The tasks
may be lazily generated as needed.

The target numbers themselves have no behavior on how \clmw processes
the tasks or enforces restricting the number of created tasks.
All target numbers do are provide a means so that the \ma can police
itself when creating tasks. The master is free to create more tasks
than specified in a target number without restriction (other than
running out of memory or other resources in the process).

Continuing the example of the \emph{echo} \ta, here is a description of the
signatures and meaning of this set of generated functions:\\

\begin{apientry}
{mw-set-target-number-for-echo \emph{value}}
{Function}
	A target number of \textit{echo} tasks the \ma would like to keep in
\clmw. Initially 0.
\end{apientry}

\begin{apientry}
{mw-get-target-number-for-echo}
{Function}
	Return the number of in memory tasks that exist for this \ta.
\end{apientry}

\begin{apientry}
{mw-pending-tasks-for-echo}
{Function}
	Return the number of tasks (both currently running and pending
	to run) for this \ta that are currently known about by \clmw.
\end{apientry}

\begin{apientry}
{mw-upto-target-number-echo}
{Function}
	A number of tasks which must be created by the \ma in order
	to reach the target number for this \ta. This function could
	return zero if the return value of \func{mw-get-target-number-for-echo} 
	is equal to or less than the return value of 
	\func{mw-pending-tasks-for-echo}.
\end{apientry}

\subsubsection{The General Target Number}

If an application author wishes to manage only the total
number of created tasks in memory independent of which \ta
they represent, then they can use the general target number
API as defined in section~\ref{general-target-number-api} on
page~\pageref{general-target-number-api}.  The number of tasks
\textit{up to} the general target number is the general target number
minus all pending tasks from any \ta.

\subsection{\label{master-algorithm}The Master Algorithm}

The macro \macro{define-mw-master} defines the \ma for a \clmw
application. There is only be one \ma per application. The \ma is
responsible for:

\begin{itemize}
\item Parsing non-\clmw command line arguments passed to the application process
\item Partitioning the main problem into sub-problems and creating tasks
\item Acquiring and managing ordered slaves
\item Calling the {\ma}'s event loop function
\item Processing the results returned by the slaves
\item Determining what to do when some tasks become unrunnable
\item Computing the final answer of the application from all results
\end{itemize}

The parameter list of this macro is:

\begin{barelisp}
(define-mw-master (argv) &body body)
\end{barelisp}

where \var{argv} is a variable--arbitrarily named and available in
the \var{body}, which will be bound to the command line argument
list. Any arguments destined to the \clmw library will have been
removed from the list before the \ma is invoked.  The arguments not
stripped out are left in the order specified on the command line.
The return value of the \ma must be an integer in the range of 0 and
255 (inclusive) and this value becomes the Unix return value for the
master process. If the return value is any other Lisp form other than
an integer between 0 and 255, the returned result will be 255.

Driving the \clmw master event loop is one of the main functions
of the \ma. The \ma accomplishes this by calling the function
\func{mw-master-loop} (or a variant of this function--see
page~\pageref{master-algorithm-api}). This function blocks and performs
network I/O to all slaves or any other background work in the \clmw
library. This function returns with a set of values that specify what
is available for the \ma to process (such as new results, arrival
or disconnection of ordered slaves, etc) only when there is some
event for the \ma to process.

\subsubsection{Slave Categorization}

The \ma can use the function \func{mw-allocate-slaves} to categorize
connecting slaves into the groups: \ord, \inter, and \un.  A connecting
slave is first used to satisfy the needs of the group \ord, then
\inter.  If enough slaves connect as to satisfy the needs for both
the \ord and \inter groups, then they are placed into the \un group.
Initially the \ord and \inter groups need 0 slaves and all slaves will
default to being placed in the \un group.

The \ord group means that the slave will \emph{only} run ordered tasks
dedicated to that slave. The \inter group means that a slave may run
unordered tasks in addition to ordered tasks dedicated to that slave
but the ordered tasks are given priority over any unordered tasks
which could run on that slave. Slaves in the \un group only run
unordered tasks.

When \inter or \ord slaves are needed and new slaves placed into
those groups, the \func{mw-master-loop} notifies the \ma (or
variant--see page~\pageref{master-algorithm-api}) that there are
ordered slaves ready for use. This notification happens with one of
the values returned by \func{mw-master-loop}. The \clmw application
author can use the function \\ \func{mw-get-connected-ordered-slaves} to
retrieve the list of connected slaves.

The function \func{mw-get-connected-ordered-slaves} returns a list
of \\ SLAVE-IDs which can be used as the \texttt{:sid} field with the
macro \macro{mw-funcall-*}.  If no ready ordered slaves are available,
then \bool{NIL} is returned. Connected ordered slaves accumulate in that
list until the \ma uses \\ \func{mw-get-connected-ordered-slave}
to retrieve them.  If at any time ordered slaves disconnect, the
function \func{mw-master-loop} will notify the \ma of the change
via one of its returned values.  The \ma can use the function
\func{mw-get-disconnected-ordered-slaves} to learn the SLAVE-IDs
of the disconnected ordered slaves. A slave may be in both lists at
once if it connected and then disconnected before the \ma was able
to retrieve either of the lists. There is no notification when an
\un slave connects or disconnects.

The \ma can free a slave from the \ord or \inter groups be using
\func{mw-deallocate-slaves} and \func{mw-free-slave}. These will move
ordered slaves to the \un group but only after they have completed
processing any assigned \ord tasks. \Note When a freed ordered slave
finishes processing the tasks assigned, it will move to the \un group
even though there may actually be more tasks destined for that slave.
In this case, the tasks will follow the task policy dictated by the
\ma when it created the task.

\subsubsection{Membership}

The membership token--an arbitrary string, is a token known between
the master and the slave. It must match for the master to accept the
slave and have it perform work. This is not a security measure. This
keeps the master and slave processes synchronized in heavy churn
situations where many masters and slaves from different computations
could be going up and down quickly. The major risk in high master
churn situations is port reuse of the master process. A port may
have master 1 bind to it, write a resource file, die, then later
master 2 from a different computation binds to the port, meanwhile
a slave using the original master 1 resource file tries to connect
to master 1 but actually connects to master 2.  Membership tokens
must be unique across \clmw application master processes running
concurrently on one machine. Unless otherwise specified with the
\OptionV{mw-resource-file}{filename} command line option, the membership
token will default to \texttt{"default-member-id"}.

\subsection{The Slave Algorithm}

The \sa is defined with \macro{define-mw-slave}.  The parameter list
of this macro is similar to \macro{define-mw-master}. This macro must
return an integer from 0 to 255 inclusive.  This portion of a \clmw
application is optional and may be left out entirely in an application.

\begin{barelisp}
(define-mw-slave (argv) &body body)
\end{barelisp}

The body of a \sa is usually a simple call to
\func{mw-slave-loop-simple}.  \func{mw-slave-loop-simple} will
wait for tasks to arrive from the master, process them, send the
results back, and will repeat until the master sends a shutdown
command. \func{mw-slave-loop-simple} returns 0 if the shutdown was
explicitly requested by the master and happened normally or 255
otherwise.

There are other slave looping function variants which allow the
slave loop function to return after a single, or group, of tasks
is finished.  These variants are used when the slave needs to set up
or tear down some files while it is working or otherwise manipulate
the environment around it in-between processing tasks. Please see
page~\pageref{slave-algorithm-api} for these other variants.

If no slave algorithm is specified in a \clmw application, then this
default \sa is automatically defined and used.

\begin{lisp}[caption=Default Slave Algorithm]
(define-mw-slave (argv)
  (mw-slave-loop-simple))
\end{lisp}

\subsection{Running a \clmw Application}

A \clmw application can be executed in two ways: interactively at a
REPL or as a dumped binary from the command line. When running in the
REPL, there should be a REPL for the master process and one each for
the slave processes. It is not recommended to start different threads
where one is the master and the rest are slaves.  From the REPL,
the \clmw entry point is the function \func{mw-initialize} which
takes a list of strings that represent the command line arguments
of the application. Running in the REPL is useful for debugging or
incremental development.

The recommended means of doing production runs with a \clmw
application is via a dumped binary created with the \clmw function
\func{mw-dump-exec}. When this function is called, the entire Lisp
image will be written into a binary and the Lisp image will exit
and any shared libraries which \func{mw-dump-exec} finds as being
local to the installation to SBCL or any used CL libraries will be
written to the current working directory. The entry point will be an
implementation specific function which does some bookkeeping and then
invokes \func{mw-initialize} with the command line arguments supplied.
In this form, the binary acts like any other client/server application
and you can easily run as many as you need.  If for some reason the
process gets an uncaught signal or other terminating error, a stack
trace created by SBCL's runtime will be emitted from the program to
facilitate debugging.

\clmw has a collection of settings which are adjusted via command line
options as described on page~\pageref{command-line-arguments}.

\subsection{Network I/O and Task/Result Size}

The underlying network implementation of \clmw is nonblocking and
fully asynchronous. A connection to a client is handled by a packet
buffer that is split into two pieces: a read buffer and a write
buffer. The initial size of each buffer is controllable.  The read
buffer can grow to a specified maximum size before the connection
is cut to the other side on account of the packet being too big.
The write buffer size is advisory at this time and only limit how
much can be written at one time instead of how large the write buffer
actually can be. This will be addressed in a future revision of \clmw.

The master process will internally group tasks into a whole network
packet and subsequently tell the slave how many results to group into
the network packet back to the master.  The grouping of tasks and
results amortizes the cost of sending data over TCP and increases
network utilization efficiency--at the cost of memory, of network
communication. It is up to the application author to understand
enough of their task and result size requirements to pick good
groupings so grouped tasks or results don't overflow the packet buffer
sizes. Understanding the scale of how many slaves will be connecting
to the master process will determine how big to make the initial
network buffer sizes and to what they should be capped as they grow.

\chapter{Downloading and Installing}

\section{Compatibility and Versioning}

\clmw will be considered in beta until it reaches the 1.0 version
number.  During this phase, the APIs or feature sets of \clmw
may change in a non-compatible ways with previous versions of
\clmw. Such compatibility or feature changes will be detailed
in the version history section of this document located in
appendix~\ref{version-history} on page~\pageref{version-history}.

\section{Supported Implementations}

\clmw is currently supported on/with: 

\begin{itemize}
\item SBCL 1.0.39.16 or later.
\item Stable releases of IOLib such as 0.7.0, 0.7.1, 0.7.2, 0.7.3 or later.
\end{itemize}

\section{Official Release Tarballs}

This web page contains all official releases of \clmw in addition to 
a live git repository of the HEAD of \clmw.

\url{http://pages.cs.wisc.edu/~psilord/lisp-public/index.html}

Manuals in PDF and HTML forms corresponding to each release exist next to
the release tarball.

\section{Installation Using a Tarball}

\begin{enumerate}
\item Unpack the tarball, e.g., \cmd{tar zxf cl-mw-0.1.tar.gz}.
\item Configure SBCL to know about the \file{*.asd} files. This may 
	entail making symlinks in your \file{\$HOME/.sbcl/systems} (or appropriate)
	directory to the \file{*.asd} files in the \clmw directory.
\item In the unpacked \clmw directory:
	\begin{itemize}
	\item \cmd{make} will make all of the examples. 
	\item \cmd{make clean} will remove all generated files.
	\item \cmd{make docs} will make the PDF and html manual output in 
		\file{doc/}.
	\item \cmd{make SBCL=/path/to/sbcl \textit{target}} will use a specific
		sbcl installation instead of the one in your path. By using this 
		mechanism, you can specify things like \cmd{clbuild lisp} if 
		that is how you start \sbcl. If you specify SBCL for the toplevel 
		Makefile, it will propagate to the Makefiles in the 
		\file{examples/*} directory
	\end{itemize}
\end{enumerate}

\chapter{Writing Applications}

A \clmw application uses the \mwpackage and exists in its own
arbitrarily named package determined by the application author.
There exist three parts to a \clmw application: one or more \tas,
a single \ma, and a single \sa.

\section{Example: Hello World}

The purpose of this minimal example is to show how to create a \ta,
a \ma, and a \sa. The \ma will create tasks and process the results
from one or more slaves which connect to the master process. The \ta we
describe simply concatenates the string arguments with another string
and returns it. Both the master and the slave processes are assumed
to be on the same machine with both binding to the localhost interface.

We start with the unsurprising ASDF file for the hello-world \clmw application.

\begin{lisp}[caption=\file{cl-mw.examples.hello-world.asd}]
(asdf:defsystem #:cl-mw.examples.hello-world
  :depends-on (#:alexandria #:cl-mw)
  :components ( (:file "package")
                (:file "hello-world"
                       :depends-on ("package"))))
\end{lisp}

For this next listing we see that \func{mw-master} and \func{mw-slave}
are functions which are used for testing or debugging in the
REPL. Notice we re-export the \mwpackage symbol \func{mw-dump-exec}
from our application package which helps us easily save the lisp image
into a binary at a later time.

\begin{lisp}[caption=\file{package.lisp}]
(defpackage #:cl-mw.examples.hello-world
  (:use #:cl #:alexandria #:cl-mw)
  (:export #:mw-master
           #:mw-slave
           #:mw-dump-exec ))

(in-package :cl-mw.examples.hello-world)
\end{lisp}

For documentation purposes, we partition the main single file of the
implementation into parts which contain the \ta, the \ma, and the \sa.

The \ta accepts a regular Lisp string and also returns one.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 1 of 4}}]
(in-package :cl-mw.examples.hello-world)

(define-mw-algorithm hello (str)
  (concatenate 'string "Hello World: " str))
\end{lisp}

The \ma creates 10 tasks into \clmw and then continues
to call \func{mw-master-loop} until 10 results have been
processed.  When \func{mw-master-loop} returns, one or
more of these \clmw functions will return meaningful data,
depending upon the application: \func{mw-get-unrunnable-tasks},
\func{mw-get-results}, \func{mw-get-connected-ordered-slaves},\\
\func{mw-get-disconnected-ordered-slaves}.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 2 of 4}}]
(in-package :cl-mw.examples.hello-world)
(define-mw-master (argv)
    (unwind-protect
         (let ((num-tasks 10)
               (num-results 0))
           (dotimes (x num-tasks)
             (let ((str (format nil "Task ~A" x)))
               (mw-funcall-hello (str))))
           (while (/= num-results num-tasks)
             (mw-master-loop)
             (when-let ((results (mw-get-results)))
               (dolist (result results)
                 (let ((payload (mw-result-packet result)))
                   (incf num-results)
                   (format t "Got result from slave: ~S~%"
                           payload)))))
           0)
      (format t "Master algo cleanup form.~%")))
\end{lisp}

The \sa is very simple in our case. The function\\
\func{mw-slave-loop-simple} simply loops inside of \clmw processing
tasks until the master tells the slave to shut down, at which point
\func{mw-slave-loop-simple} returns 0 and the slave exits with
that return code. We could have left off this definition of a slave
algorithm altogether and used the default slave algorithm in a \clmw
application. We included it here as demonstration of how to write one.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 3 of 4}}]
(define-mw-slave (argv)
  (unwind-protect
       (mw-slave-loop-simple)
    (format t "Slave algo cleanup form.~%")))
\end{lisp}

We additionally specify two helper functions which are not part of
\clmw, nor technically the application, but allow us ease of debugging
and testing the application in the REPL.

\begin{lisp}[caption=\file{hello-world.lisp: \bold{Part 4 of 4}}]
(defun mw-master ()
  (mw-initialize 
    '("--mw-master" "--mw-slave-task-group" "10"
                    "--mw-master-host" "localhost"
                    "--mw-slave-result-group" "10")))

(defun mw-slave (port)
  (mw-initialize 
    `("--mw-slave" "--mw-master-host" "localhost"
                   "--mw-master-port"
                   ,(format nil "~D" port))))
\end{lisp}

\section{Running Hello-World in the REPL}

Now, let's run this example in the REPL so we can see how it
works. First, we'll set up and run the master process. We call our
master helper function to start the master process.  We're packaging
together 10 tasks to an idle slave and expecting 10 results back from
any particular slave. Otherwise 1 task will be sent and 1 result sent
back from the slave. Grouping the tasks or results together makes the
network communication more efficient.  The master is told to start
up on the \texttt{localhost} interface. There is no method to start
the master bound to all interfaces.

In the log output below, the member id token of the master and
slave is \bold{``default-member-id''}. In normal use, this should
probably be changed to be unique to the specific master/slave
computation. Please see the section on command line arguments on
page~\pageref{command-line-arguments} for how to do this.

\small
\begin{verbatim}
> sbcl
This is SBCL 1.0.39.16, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
* (require :cl-mw.examples.hello-world)
[ Lots of output on compiling and loading libraries ]

* (use-package :cl-mw.examples.hello-world)

T

* (mw-master)
07/20/2010 23:15:42 [A] INIT MASTER "default-member-id"
07/20/2010 23:15:42 [A] MASTER READY 127.0.0.1:52942
\end{verbatim}
\normalsize

At this point, the master process has already created some hello
world tasks and is waiting for some slaves to connect. The output
lines with \texttt{[A]} in them are emitted as an audit trail by the
\clmw library.  The \bold{``default-member-id''} is the membership
token of the master which the slave must match. Let's start up a slave
with our helper slave initialization function and pass in the port
number of the master process---because for this example the helper
slave function assumes localhost.

\small
\begin{verbatim}
> sbcl
This is SBCL 1.0.39.16, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
* (require :cl-mw.examples.hello-world)
[ Lots of output on compiling and loading libraries ]

* (use-package :cl-mw.examples.hello-world)

T

* (mw-slave 52942)
07/20/2010 23:23:46 [A] INIT SLAVE "default-member-id"
07/20/2010 23:23:47 [A] MASTER <- CONNECTED TO 127.0.0.1:52942 \
                        FROM 127.0.0.1:47768
07/20/2010 23:23:47 [A] MASTER -> ID SLAVE-0
07/20/2010 23:23:47 [A] MASTER -> 10 tasks (10 grouping)
07/20/2010 23:23:47 [A] MASTER <- 10 results
07/20/2010 23:23:47 [A] MASTER -> SHUTDOWN
Slave algo cleanup form.
07/20/2010 23:23:47 [A] FINI SHUTDOWN "default-member-id"
0
* 
\end{verbatim}
\normalsize

The last number is the return code of the slave function.

Meanwhile, let's see what the master emitted:

\small
\begin{verbatim}
07/20/2010 23:23:47 [A] NEW-CLIENT -> 127.0.0.1:47768
07/20/2010 23:23:47 [A] SLAVE-0 127.0.0.1:47768 -> \
                        ["default-member-id"] \
                        :connecting [:unordered]
07/20/2010 23:23:47 [A] SLAVE-0 -> :idle
07/20/2010 23:23:47 [A] SLAVE-0 <- 10 tasks
07/20/2010 23:23:47 [A] SLAVE-0 -> :busy
07/20/2010 23:23:47 [A] SLAVE-0 -> 10 results
07/20/2010 23:23:47 [A] SLAVE-0 -> :idle
Got result from slave: "Hello World: Task 0"
Got result from slave: "Hello World: Task 1"
Got result from slave: "Hello World: Task 2"
Got result from slave: "Hello World: Task 3"
Got result from slave: "Hello World: Task 4"
Got result from slave: "Hello World: Task 5"
Got result from slave: "Hello World: Task 6"
Got result from slave: "Hello World: Task 7"
Got result from slave: "Hello World: Task 8"
Got result from slave: "Hello World: Task 9"
Master algo cleanup form.
07/20/2010 23:23:47 [A] SLAVE-0 <- TRY-SHUTDOWN
07/20/2010 23:23:47 [A] SLAVE-0 -> :shutting-down
07/20/2010 23:23:47 [A] SLAVE-0 -> :disconnected
07/20/2010 23:23:47 [A] EOF -> 127.0.0.1:47768
07/20/2010 23:23:47 [A] FINI SHUTDOWN "default-member-id"
0
*
\end{verbatim}
\normalsize

\Note The audit lines have been reformatted slightly to fit. They do
not have the traditional shell line continuation characters in them.

We see that the master had packaged all ten tasks into one packet and
sent it to the slave. After getting the results--also in one packet,
back, it printed them out. At this point the results have equaled
the tasks in the \ma and it returns. \clmw enters the shutdown
phase where it actively tried to shut off all known slaves and then
exit with the return code the \ma generated. If a severe problem
arose during shutdown, then the return code will be set to 255.

\section{Producing an Executable}

The \mwpackage exports the function \func{mw-dump-exec} which saves
the Lisp image as an executable to the current working directory. We
recommend that this function be re-exported from the application
package built on top of the \mwpackage as shown previously in the
ASDF file for this example. Exporting this function makes it trivial
to produce an executable---one just \bold{require}s the package,
then \bold{use-package}s it, and then calls \func{mw-dump-exec}
to produce the binary. 

\func{mw-dump-exec} simplifies collecting required libraries that
may not be present on the slave system.  \func{mw-dump-exec} will
copy any currently loaded libraries with an absolute path into the
current working directory. For libraries without any path, it will
approximate the search algorithm used by \syscall{dlopen} to find an
absolute path for the library and then copy it to the current working
directory. \func{mw-dump-exec}, with the \keyword{ignore-libs} keyword
argument, can be told to ignore specific libraries loaded by the lisp
image. One would supply a list of strings representing unqualified
library names to be ignored. Libraries can also be remapped, with
the \keyword{remap-libs} keyword argument, from their unqualified
name to a specific path. An association list should be supplied
with \keyword{remap-libs} which maps unqualified library names to
absolute paths. Ignoring a library overrides a remap of a library,
and a remap of a library overrides the auto detection of the library's
absolute path.  \func{mu-dump-exec} will update the Lisp image to
look for the dumped libraries in the path \file{./} when the saved
executable is started.

How the lisp image is started before the executable is produced is
important.  We start \sbcl up with the \Option{disable-debugger} option
which tells \sbcl to dump a stack trace and exit when something has
gone wrong in the executable---such as the signaling of an unhandled
condition. Otherwise, \sbcl will drop into an interactive debugging
session and wait for input to arrive. Disabling the debugger prevents
the executable from having a problem and then consuming valuable
compute time on a resource waiting for input which will never come.

Dropping into the debugger is one of a few things in the execution
environment that can be altered with various command line options
to \sbcl. Another common adjustment to set is how big the heap is in
the Lisp image runtime.  The default runtime heap size is operating
system specific. On the Linux machine upon which I developed \clmw,
it was 512MB and so for each invocation of the master and slave
executable, about 512MB of memory will be requested from the operating
system---even if it isn't all used by the application. Depending upon
your \ma and \tas, you may need to tune the runtime heap size to fit
the computation requirements. Please see the \sbcl manual for more
tunable options as needed by your computation.

\small
\begin{verbatim}
> sbcl --disable-debugger
This is SBCL 1.0.39.16, an implementation of ANSI Common Lisp.
More information about SBCL is available at <http://www.sbcl.org/>.

SBCL is free software, provided as is, with absolutely no warranty.
It is mostly in the public domain; some portions are provided under
BSD-style licenses.  See the CREDITS and COPYING files in the
distribution for more information.
* (require :cl-mw.examples.hello-world)
[ Lots of output on compiling and loading libraries ]

* (use-package :cl-mw.examples.hello-world)

T

* (mw-dump-exec)

######################################
# Processing loaded shared libraries #
######################################
Shared-library: /home/psilord/content/code/lisp/clbuild/source\
                /iolib/src/syscalls/libiolib-syscalls.so...\
                dumping...fixating.
Shared-library: librt.so...looking up...found \
                /usr/lib/librt.so...dumping...fixating.

########################################################
#  Please package these libraries with your executable #
########################################################
./librt.so
./libiolib-syscalls.so

####################################
# Writing Master/Slave executable #
####################################
[undoing binding stack and other enclosing state... done]
[saving current Lisp image into ./a.out:
writing 3512 bytes from the read-only space at 0x01000000
writing 2256 bytes from the static space at 0x01100000
writing 38322176 bytes from the dynamic space at 0x09000000
done]
\end{verbatim}
\normalsize

\func{mw-dump-exec} iterated over all of the shared libraries being
used by the Lisp image. \func{mw-dump-exec} determined that the shared
library \file{libio-syscalls.so} used by IOLib (a package needed by
\clmw) must be included and the actual library file is copied into the
current working directory. Then the Lisp image is adjusted to look in
the path \file{./} for \file{libio-syscalls.so}.  \func{mw-dump-exec}
noticed that \file{librt.so} didn't have an absolute path but had a
successful search for an absolute path to the library.  This library
is also copied to the current working directory and the lisp image
adjusted to find it. If \func{mw-dump-exec} isn't told otherwise, the
name of the binary it dumps is \file{a.out}. You can supply a different
executable name to \func{mw-dump-exec}, see page~\pageref{mw-dump-exec}
for details.

If this executable is supplied with the same arguments
to \func{mw-initialize} as defined in the helper function
\func{mw-master} and another invocation started with the same
arguments to \func{mw-initialize} as defined in the helper function
\func{mw-slave} (adjusting for the master's host and port!), then
you will see similar output as the slave executes the master's tasks.

Here we see the executable and the shared libraries with which it should be
bundled when moved to another machine for execution:

\small
\begin{verbatim}
> ls a.out *.so
-rwxr-xr-x 1 psilord psilord 38948892 Jul 20 23:44 a.out*
-rw------- 1 psilord psilord     7235 Jul 20 23:44 libiolib-syscalls.so
-rw------- 1 psilord psilord    30684 Jul 20 23:44 librt.so
\end{verbatim}
\normalsize

\Important Any dumped shared libraries \bold{must} exist in the
current working directory when the main binary is invoked for them to
be found by the restarting binary. Relative paths and the environment
variable \EnvVar{LD\_LIBRARY\_PATH} do not work properly.

\section{The Audit File}

The master and slave process both can write their
audit trail to a specified file. This is done with the
\OptionV{mw-audit-file}{file-name} command line option. When this
option is used, every written line above with an \texttt{[A]} in it
will be written to the specified audit file. Any other output that the
\ma or \sa creates will go to \var{*standard-output*} or to wherever
that is bound.

\Limitation The audit files do not rotate and can grow unboundedly. The
audit file will be appended to if it exists upon start of the master
or slave process.

\clmw does minimal statistics bookkeeping. The audit files can be used
to answer questions about the application's run. For example, how many
slaves are connected, what is the slave churn rate, on what subnet are
the slaves, or how many tasks were processed for a given time interval.

\Note The format of the audit file may change in a future revision of \clmw.

\chapter{Interfacing with Existing Batch Systems}

\clmw is designed to work with existing batch systems.  \clmw has no
provision for starting up slaves on remote machines, moving files
between machines, detecting and killing run away slaves, managing
user identity, storing or transmitting credentials, or enforcing
authorization policies for resource use.  These, and many other
features, are general features which batch systems usually provide.
In general, batch systems provide very robust mechanisms for each of
these features and are well suited to handle many edge cases which
show up in practice. Usually a \clmw application will be sharing
resources with other applications across a common cluster of machines.

What \clmw does provide is a means for communicating to a batch system
called the \rfile.  The master process, when configured to do so,
periodically writes information into the \rfile, including liveness
of the master process, if the computation is still in progress, how
many slaves the master desires, and how to start up those slaves.
The master process adjusts the resource requirement information in the
file based upon the outstanding workload and the slaves successfully
started by the batch system.

The \rfile is written when the command line option\\
\OptionV{mw-resource-file}{file-name} is used with the
master process. By default the master will rewrite it
every 300 seconds (5 minutes) with new information. This
can be controlled by the command line option\\
\OptionV{mw-resource-file-update-interval}{integral-seconds}.

The \rfile contains information in Lisp form and is intended to be read by
another process specific to the batch scheduler whose responsibility it
is to acquire resources from said batch scheduler. The batch scheduler
is directly notified in the \rfile if the {\ma}'s computation is in
progress or finished.

The slave process can also read the \rfile in order to determine the
master host, port, and member-id to which it should connect and if
the computation is still in progress or finished.  Depending upon the
batch scheduler, having the slave read the \rfile directly can be a
very helpful because the dynamic connection information needed by the
slave is available in the file. There is no requirement to adjust
meta-information for the slave (e.g., its command line arguments
which may specify a new master ip:port combination) through the batch
system itself.

The internals of the \rfile are described on
page~\pageref{resource-file}.

\section{Condor}

Condor is a versatile, robust, and free batch scheduling system
available from \url{http://www.cs.wisc.edu/condor}. It can maintain
high job throughput for tens of thousands of jobs on tens of thousands
of resources. Condor's built in mechanisms for file transfer,
job execution policies, and robustness mechanisms make it a good
distributed computing platform on which to run \clmw applications.
We describe a simple application of Condor which provides a reliable
execution platform for a \clmw application.

\subsection{Interfacing \clmw with Condor}

Condor can be told to transfer the job's input files to the remote
execute node just before the job is about to start. Condor will do
this each time a job tries to run when it has been sitting idle in
the queue. We use this fact to copy over the \rfile written by the
master over to the slave so the slave knows where to connect.

We use a Condor feature that can control when a terminated job is
to removed from the queue. We forbid the slave job to be removed
from the queue unless the slave gets told to shutdown by the master
or otherwise exits with the return code of zero.  If the master dies
without producing a completed answer, the slaves, having noticed that
the master closed the connection without having been told to explicitly
shut down, will exit with a non-zero status. The slave jobs will remain
in the job queue due to the Condor enforced job policy. If the slave
runs again and tries to connect using a stale resource file (due to
the master not running for an extended period of time), the slave will
again exit with a non-zero status value, again remaining in the queue.

We also submit the master process itself as a job into the Condor
system. The master will always run on the submit node as opposed to
being shipped to an execute node. This allows the master access to
the needed input files or other resources usually only found on the
submission machine and owned by the submitter of the job. We do not
perform the same type of job policy for the master as we did for the
slaves. If the master exits with any return code, it will be removed
from the job queue. However, in the event of machine reboot (or many
other types of failures), Condor will, when it starts running again,
know that the master and slave processes were present in the job
queue. It will restart the master and again find more resources
for the slave jobs. When the master restarts it will write a new
\rfile. When a slave runs again, the new \rfile gets moved to it
and it will connect with the currently running master. Finally,
if the master has finished and written the final update into the
\rfile stating the computation is finished, then any slaves that
start up with that particular \rfile will immediately exit with a
status zero. This allows the slaves to be removed from the queue. If
a slave is told to shutdown properly by the master, and does so, then
it will exit with an exit code of 0 and also be removed from the queue.

The combination of the slave job policy and the restart robustness
of the master makes \clmw jobs reliable. In the event of a restart
of the master process, the entire computation will restart. However,
the entire computation will reliably restart and run until it finally
completes.

The particular interface described in this section is: simple, doesn't
make full use of the information the \rfile, and wastes compute time
on the execution nodes during the time the master process is down. It
could be extended with an actual process outside of \clmw and managed
by Condor which watches the \rfile and actively submits and removes
slaves from Condor based on the master's current resource needs.

\subsubsection{A Simple Interface to Condor}

This example describes the Condor interface for the \exec{ping}
example supplied with \clmw.

There are two Condor submit files, one for a single master process,
and one for a static cluster of slave processes. The master will write
a \rfile and the slaves, using file transfer, will read it and know
where to connect.  No dynamic adjustment of resource acquisition is
done in this example.

\subsubsection{The Master Process}

The following submit file details how the master process is to be run. This
file is given to Condor's \exec{condor\_submit} which submits the job into
Condor's job queue on the local machine.

\begin{verbatim}
# Begin master.sub
universe = scheduler
executable = ./ping
arguments = --mw-master \
--mw-slave-task-group 100 \
--mw-slave-result-group 100 \
--mw-resource-file resource-file.rsc \
--mw-slave-executable ping \
--mw-audit-file master.$(CLUSTER).$(PROCESS).audit \
--mw-member-id $(CLUSTER).$(PROCESS)

output = master.$(CLUSTER).$(PROCESS).out
error = master.$(CLUSTER).$(PROCESS).err
log = master.$(CLUSTER).$(PROCESS).log

notification = NEVER

queue 1
# End master.sub
\end{verbatim}

Each line will be described as to its effect on the job submission.
\\

\begin{explainline}
{universe = scheduler}
The job is marked to be a scheduler universe job. It will start immediately
and only on the machine where this job is submitted.
\end{explainline}

\begin{explainline}
{executable = ./ping}
The executable Condor will use when executing this job.  Condor and
the \exec{ping} executable will assume the needed libraries, if
any, associated with the \exec{ping} program are present in the
same directory as the executable.
\end{explainline}

\begin{explainline}
{arguments = --mw-master \textbackslash \\ \indent
--mw-slave-task-group 100 \textbackslash \\ \indent
--mw-slave-result-group 100 \textbackslash \\ \indent
--mw-resource-file resource-file.rsc \textbackslash \\ \indent
--mw-slave-executable ping \textbackslash \\ \indent
--mw-audit-file master.\$(CLUSTER).\$(PROCESS).audit \textbackslash \\ \indent
--mw-member-id \$(CLUSTER).\$(PROCESS)}
This is the complete list of command line arguments supplied to the
master process when it is executed by Condor.

The meaning of the \texttt{--mw-*} arguments in numerical order are:
\begin{enumerate}
\item Must be first and specifies that this invocation of the \exec{ping}
	binary is the master process.
\item Number of tasks that the master will pack into one network
	packet to a slave.
\item Number of results that the slave will pack into one network
	packet to the master.
\item Specify the resource file.  The \rfile path must be unique to each
	\clmw computation submitted to the same scheduler daemon
	in Condor.  The path must match between the master's submit
	file and the slave's submit file.
\item We explicitly specify the slave executable name. Otherwise, the
	master would try to determine the name of itself when it is
	running in order to find its own executable to use as the
	slave executable in the \rfile. The explicit specification of the slave
	executable is necessary because Condor specifies a different
	name for the executable when executing it.
\item An audit file is specified based upon the cluster and process
	id of the job.	It will be filled with information about who
	and how the slaves connect and what work is given to them. We
	use Condor's \$(CLUSTER) and \$(PROCESS) macros, which are
	unique per job submitted, to assign a unique identifier to
	this file.
\item Using Condor's \$(CLUSTER) and \$(PROCESS) mechanism, we assign a
	unique identifier to the master. This identifier will be written into
	the \rfile so that the slaves can authenticate themselves to
	the master.
\end{enumerate}
\end{explainline}

\begin{explainline}
{output = master.\$(CLUSTER).\$(PROCESS).out}
Any standard output written by the \ma will be written here.
\end{explainline}

\begin{explainline}
{output = master.\$(CLUSTER).\$(PROCESS).out}
Any standard error output written by the \ma will be written here.
\end{explainline}

\begin{explainline}
{log = master.\$(CLUSTER).\$(PROCESS).log}
This file is written by Condor and is a sequential record of a job's lifetime
in Condor. A sample of the events which can happen to a job are: submission,
execution, termination, held, released, etc. This file is a very useful
debugging and tracking tool to find out the state in which a job may be.
\end{explainline}

\begin{explainline}
{notification = NEVER}
No matter how this job completes, do not send an email to the
account which submitted this job. Valid options are \bold{ALWAYS},
\bold{COMPLETE} (the default if \texttt{notification} is not
specified), \bold{ERROR}, and \bold{NEVER}.
\end{explainline}

\begin{explainline}
{queue 1}
This will submit one cluster of jobs into Condor with only one job in the
cluster.
\end{explainline}

When this job is submitted, it should start immediately and create
the \rfile \file{resource.rsc}. After this file is in existence,
the slaves can be submitted.

\subsubsection{The Slave Processes}

The following submit file submits a static cluster of vanilla jobs
which are the slaves.

\begin{verbatim}
# Begin slaves.sub
universe = vanilla
executable = ./ping
arguments = --mw-slave \
--mw-resource-file resource-file.rsc

output = slaves.$(PROCESS).out
error = slaves.$(PROCESS).err
# All slaves will share a log file.
log = slaves.log

should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_input_files = libiolib-syscalls.so,resource-file.rsc

notification = NEVER

on_exit_remove = (ExitBySignal == False) && (ExitCode == 0)

queue 1000
# End slaves.sub
\end{verbatim}

We describe the interesting lines in this submit file.
\\

\begin{explainline}
{universe = vanilla}
This fixates a set of features for this job in the Condor system which
state that the job can run on any suitable execute machine in the pool.
\end{explainline}

\begin{explainline}
{arguments = --mw-slave \textbackslash \\ \indent
--mw-resource-file resource-file.rsc}
The meaning of the \texttt{--mw-*} arguments in numerical order are:
\begin{enumerate}
\item Must be first and specifies that this invocation of the \exec{ping}
	binary is a slave process.
\item Specifies a resource file the slave will use to contact the master 
	process and identify itself.
\end{enumerate}
\end{explainline}

\begin{explainline}
{should\_transfer\_files = YES}
This states that Condor is responsible for moving any files the job
needs or produces during its execution. If not specified it means
there is a common file system between the submit machine and the
execute machine that the job can access.
\end{explainline}

\begin{explainline}
{when\_to\_transfer\_output = ON\_EXIT}
This specifies that Condor only cares about the output a job produces when
a job completes.
\end{explainline}

\begin{explainline}
{transfer\_input\_files = libiolib-syscalls.so,resource-file.rsc}
Any input files needed by the job are specified here. We specify
the shared libraries the slave executable needs in addition to the
resource file. Condor will transfer the most recent versions of these
input files each time the job starts.
\end{explainline}

\begin{explainline}
{on\_exit\_remove = (ExitBySignal == False) \&\& (ExitCode == 0)}
This implements the job policy previously mentioned. Only allow the job be
removed from the queue when it hasn't exited by a signal and the exit code
of the job is zero. If the job exits for any other reason, it will remain 
in the job queue and be eventually restarted.
\end{explainline}

\begin{explainline}
{queue 1000}
Submit one cluster with 1000 jobs in it into Condor.
\end{explainline}

In summary, one thousand jobs will be submitted into this cluster.
The \keyword{slaves-needed} setting in the \rfile is ignored, as there
is no overseer watching the \rfile and managing resource acquisition
on behalf of the \ma.  The \rfile is transmitted as an input file
and under Condor this means to transmit it anew every time the job is
rerun. Condor also send over any shared libraries or other files the
executable needs.  These slaves will stay in the queue until they
either connect to a master and the master tells it to shut down,
or because the master wrote \texttt{:computation-status :finished}
into the \rfile and the slave reads the file.  In addition, we specify
the \texttt{on\_exit\_remove} policy for the job; the slave will only
be removed from the queue if the slave had not exited with a signal
and the exit code was zero as requested by the master.  The output
of the slaves will be the standard out of the \sa. Since no audit
file is specified, the auditing information will go to the standard
out of the process.

\subsection{Environmental Requirements}

Running binaries across a host of machines which differ in OS
revisions, physical capabilities, and network will bring to the
forefront scalability and binary compatibility problems. Here we
describe a few common problems and their solutions.

\subsubsection{Memory Requirements}

Depending upon the memory capabilities of the resource slots in
the pool (suppose they only have 384MB each), a slave may run once,
consume 512MB which Condor records as the memory usage for the job,
be preempted for some reason, and then never run again because no
slot in the pool will accept a 512MB job anymore.

This is fixed by either adding \texttt{Requirements = Memory > 0}
(or whatever fits your needs) to the slave's submit file or adjusting
the fixed runtime heap size with command line arguments to \sbcl
when you create the executable. The latter choice is safer since it
models the true resource requirements your application needs and does
a better job of preventing thrashing. The former is more useful for
testing purposes.

\subsubsection{Network or Disk Bandwidth}

Another environmental concern is the network or disk bandwidth of the
submit machine as potentially thousands of slaves simultaneously have
their executables, shared libraries, and other files transferred from
the submit machine and onto the execute slots.  In practice this often
isn't a problem, but it is good to know what to do if it becomes one.

The \textit{condor\_schedd} config file entries
\texttt{JOB\_START\_DELAY} and\\ \texttt{JOB\_START\_COUNT} can be used
to limit the job start rate to restrict network and disk bandwidth
when bursts of jobs begin running.

\subsubsection{Dynamic Linking}

Since a \clmw application is a dynamically linked binary, it will need
to find and load its required libraries at run time.  When the binary
is moved from the submit host to the execute host, the execute host
may not have a required dynamic library available, or more rarely,
a required kernel syscall interface the job needs. In this event, the
job (in our case, the slave) will (often) die with a SIGKILL and go
back to idle (due to our \texttt{on\_exit\_remove} policy). It could
be possible for a slave to continuously match to a machine upon which
it cannot run. In this situation the slave will accumulate runtime
but make no forward progress. The preferred solution is to package
your libraries with your job. In the rare cases where this will not
be sufficient, you may have to restrict the set of machine upon which
your job runs.  Please read section 2.5 in the Condor manual for how
to specify this kind of a requirement for your job.

\chapter{Technical Specification}

\section{Command Line Arguments}
\label{command-line-arguments}

These are the command line arguments the \clmw library accepts. These
command line arguments are stripped from the argv before the argv is
handed to the \ma.

\begin{description}
\item[\Option{mw-help}]
    Emit the usage and exit.
\item[\Option{mw-version-string}]
    Emit the version string and exit.
\item[\Option{mw-master}]
    Run the executable in Master Mode. Required if \Option{mw-slave} is not set
	and must be first on the command line.
\item[\Option{mw-slave}]
    Run the executable in Slave Mode. Required if \Option{mw-master} is not set
	and must be first on the command line.
\item[\OptionV{mw-master-host}{ip-address-or-hostname}]
    When in Master Mode, it is the interface (either the hostname or
    the ip address) to which the master should bind and is emitted to
    the resource file if any such file is written.
    When in Slave Mode, it is the hostname, or ip address, to which
    the slave process should connect and get work.
\item[\OptionV{mw-master-port}{port}]
    To which port should the slave connect for work.
\item[\OptionV{mw-max-write-buffer-size}{size-in-bytes}]
    How big the network writing buffer should be before rejecting the write.
\item[\OptionV{mw-max-read-buffer-size}{size-in-bytes}]
    How big the network reading buffer should be before rejecting the read.
\item[\OptionV{mw-client-timeout}{seconds}]
    How many seconds should the master wait for a client to respond
    when the master is expecting a response.
\item[\OptionV{mw-audit-file}{filename}]
    A file in which the audit trail of the process is stored.
\item[\OptionV{mw-resource-file}{filename}]
    Describes the resources needed by the master for a higher level batch
    system to honor.\\
	When in master mode this file contains information concerning:
	\begin{itemize}
		\item The time stamp of when the file was written.
		\item The member id of the master group.
		\item The update interval of when this file will be written again.
		\item How many slave processes are needed by the master.
		\item The full path to the slave executable.
		\item The complete arguments to the slave in order for it to
			connect to the currently running master process which 
			produced this file.
    \end{itemize}
    When in slave mode:
	\begin{quotation}
      Determine the master-host, master-port, and member-id to which
      the slave should connect by reading it from the resource file.
      The ordering of this command line option in relation to
      \Option{mw-master-host}, \Option{mw-master-port}, and 
	  \Option{mw-member-id} is
      important. If \Option{mw-master-host}, \Option{mw-master-port}, and/or
      \Option{mw-member-id} are specified before this argument then the
      resource file will overwrite the command line specification,
      and vice versa. If the resource file does not exist, then this
      knowledge is ignored (but warned about) if \Option{mw-master-host}
      and \Option{mw-master-port} are present.
	\end{quotation}
\item[\OptionV{mw-resource-file-update-interval}{seconds}]
    How many seconds between updating the resource file with current
    information.
\item[\OptionV{mw-slave-task-group}{positive-integer}]
    How many tasks are grouped into a network packet being sent
    to a slave process. If the packet is larger than the maximum
    size of the read buffer of the slave, the slave will abort the
    read. Defaults to 1.
\item[\OptionV{mw-slave-result-group}{positive-integer}]
    How many completed results should be grouped into a network packet
    being sent from the slave to the master. If the packet is larger than the
    maximum size of the read buffer for the master, then the master will
    abort the connection to the slave. Defaults to 1.
\item[\OptionV{mw-member-id}{string}]
    This is a token which must match between the slave and the master. It is
    used to insecurely identify a working group of masters and slave. In a
    harsh environment with many masters and slaves going up and down, this
    acts as a simple sanity check that the correct slaves are connected to the
    correct master process. Default is the string "default-member-id".
\item[\OptionV{mw-slave-executable}{path-to-executable}]
    This specifies the absolute path to a slave executable. It is used
    when writing the resource file only.
\end{description}

\section{The API}

The \clmw library is in the \mwpackage and it is used by the application
package built on top of \clmw. The exported symbols in the \mwpackage are:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{The Task Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%
\begin{apientry}
{define-mw-algorithm \emph{name} (\emph{parameters*}) \&body \emph{body}}
{Macro}
Defines a \ta with name \emph{name}. The arguments passed to this
call are those which were passed into the \genmacroname{mw-funcall-}
form for the \ta.

\Limitation The \emph{parameters} list is restricted to having zero
or more \emph{required} parameters and one additional and optional
lambda list keyword. There may be any number of parameters and their
init-forms associated with the lambda list keyword.

\Limitation Supplied-p-parameters are not supported in the lambda list.

\Limitation A \ta may not return multiple values or a
function or closure. The latter restriction is due to the inability
to serialize a closure from the slave to the master.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Task Computation Function Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{apientry}
{\textit{name} \textit{parameters*}}
{Function}
This is the function which actually performs the work of the \ta. It
accepts the parameters specified and returns the last expression in
the body supplied to the \ta macro.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Task Submission Macro Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-funcall-\textit{name} (\emph{parameters}) \&key\\
\indent \emph{sid} \emph{tag} \emph{do-it-anyway} (\emph{retry} t)}
{Macro}
This is a destructuring macro which will insert a single new task
of the \ta named by \emph{name}  into \clmw. The \emph{parameters}
are in the same order as the parameter list for the defined \ta and
are evaluated before being packed into the task structure. The other
parameters describe a behavior which together constitute the \tp for
a submitted task.

\begin{description}
\phlabel{task-policy}
\item[sid \textit{SLAVE-ID}] Send the task to a specific slave denoted by 
					\textit{SLAVE-ID}.
                    If \bool{NIL}, this task is considered \un, otherwise it is 
					a \ord task. 
\item[tag \textit{FORM}] A form which will appear unchanged in the result
			structure associated with the computed task. The default is 
			\bool{NIL}.
\item[do-it-anyway {[T \textit{or} NIL]}] If the task was a 
							\ord task and the slave disconnected, then should
							this task be moved into the \un group (yes if T),
							or become unrunnable (yes if \bool{NIL})? 
							By default \ord tasks become unrunnable if the 
							associated slave is disconnected. 
\item[retry {[T \textit{or} NIL]}] If an unordered task was assigned to a 
			slave and the slave went away, then this controls if we should
			retry on a different slave or if the task becomes unrunnable. If
			this test passes then :do-it-anyway is consulted in the case of
			\ord tasks. 
\end{description}
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Task Policy Specification Macro Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-with-task-policy-for-\textit{name} (\emph{task-adder-func-symbol} \\
\indent \&key \emph{sid} \emph{tag} \emph{do-it-anyway} (\emph{retry} t))\\
\indent \&body}
{Macro}
This destructuring macro binds a task submitter function that honors
the \tp specified by the optional keyword arguments to the symbol
\emph{task-adder-func-symbol}. The symbol \emph{task-adder-func-symbol}
is lexically available in the \emph{body} of the macro. This function
is used to add tasks with the \tp specified to \clmw.

\Tp keywords which are not specified default to their values as defined
for \macro{mw-funcall-\emph{name}} on page ~\pageref{task-policy}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Specific Target Number API Generated by \macro{define-mw-algorithm}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%
\begin{apientry}
{mw-set-target-number-for-\textit{name} \emph{value}}
{Function}
Sets the target number for the \ta specific to \emph{name} to
\emph{value}, which is clamped to zero or greater.  This represents
the maximum number of pending tasks for this \ta that
the \ma would like to keep in memory at once. This target number is advisory
and the \ma can insert more tasks than indicated by the target number. The
default target number for any specific \ta is 0.  
\end{apientry}

%%%
\begin{apientry}
{mw-get-target-number-for-\textit{name}}
{Function}
Returns the target number for the number of desired tasks to
keep in memory for the \ta specific to \emph{name}.
\end{apientry}

%%%
\begin{apientry}
{mw-pending-tasks-for-\textit{name}}
{Function}
Return how many tasks are in memory (and not running on any slaves) specific
to the \ta \emph{name}.
\end{apientry}

%%%
\begin{apientry}
{mw-upto-target-number-\textit{name}}
{Function}
Returns the number of tasks the \ma would have to create in order
to reach the desired target number for \ta \emph{name}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{\phlabel{general-target-number-api}The General Target Number API}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-set-target-number \emph{value}}
{Function}
Sets the general target number for all tasks regardless of \ta. This is
only advisory and more tasks could be created into \clmw by the \ma.
\end{apientry}

%%%
\begin{apientry}
{mw-get-target-number}
{Function}
Return the current value of the general task target number. The
default value for the general target number is 0.
\end{apientry}

%%%
\begin{apientry}
{mw-pending-tasks}
{Function}
Return how many tasks of any kind are waiting to be scheduled to slaves.
\end{apientry}

%%%
\begin{apientry}
{mw-upto-target-number}
{Function}
Return how many tasks of any kind should be created by the master in order
to reach the general target number for all tasks.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{\phlabel{master-algorithm-api}The Master Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{define-mw-master (\emph{argv}) \&body \emph{body}}
{Macro}
Defines the \ma for the application of which there may only be one.
When the \ma has finished computation, it must return an integer from 0 to 255
which will become the return code of the process. If this doesn't happen,
the return integer will be 255.

\Note If no master algorithm is specified in a \clmw application. An
audit line will be emitted stating this fact and the master computation
will shut down immediately. A return code of 255 will happen in
this case.

Parameter \emph{argv} will be the command line arguments passed to
the executable or to \func{mw-initialize} with the \clmw specific
arguments stripped out.
\end{apientry}

%%%
\begin{apientry}
{mw-master-loop \&key (\emph{timeout} .05)}
{Function}
Enter the \clmw system loop processing I/O and other library tasks until
one or more of these events happen:
\begin{itemize}
\item Some tasks become unrunnable.
\item There are pending results from slaves.
\item Sequential slaves have connected to the computation.
\item Sequential slaves have disconnected from the computation.
\end{itemize}

When one or more of these events happen the function will return the
4 values: 

\begin{enumerate}
\item Number of unrunnable tasks
\item Number of ready results
\item Number of newly connected and unprocessed ordered slaves
\item Number of newly disconnected and unprocessed ordered slaves
\end{enumerate}

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.  In the case of this function, it means we perform
bookkeeping work inside of the \clmw library and enter back into the
loop if no meaningful events occurred. Setting this value too low will
result in excessive CPU usage by the master process.

\end{apientry}

%%%
\begin{apientry}
{mw-master-loop-iterate \&key (\emph{timeout} .05)}
{Function}
Enter the \clmw system loop processing a \emph{single} pass of network
I/O and other library tasks. After this call one or more of the same events
as described in \func{mw-master-loop} \emph{may} have happened.

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.  In the case of this function, it means we return
the 4 values as described in \func{mw-master-loop}. Setting this value
too low could result in excessive CPU utilization.

\end{apientry}

%%%
\begin{apientry}
{mw-get-unrunnable-tasks}
{Function}
Return all currently unrunnable task structures in a list or \bool{NIL} if none.
\end{apientry}

%%%
\begin{apientry}
{mw-get-results}
{Function}
Return all currently finished result structures in a list or \bool{NIL} if none.
\end{apientry}

%%%
\begin{apientry}
{mw-get-connected-ordered-slaves}
{Function}
If there are any connected ordered slaves ready for use, this will
retrieve the list of slave ids or \bool{NIL} if none. In practice each slave
id is a string, but generally they are an opaque data structure used
to uniquely identify a slave. You should use \func{equal} to check
quality between slave ids.
\end{apientry}

%%%
\begin{apientry}
{mw-get-disconnected-ordered-slaves}
{Function}
If any ordered slaves have become disconnected, return a list of
their slave ids. You may use \func{equal} to compare against other
slave ids.
\end{apientry}

%%%
\begin{apientry}
{mw-allocate-slaves \&key (\emph{amount} 1000) (\emph{kind :unordered})}
{Function}
There are three kinds of groups for which slaves can be allocated:
\ord, \inter, \un.  When a slave initially connects for work, it is
placed into one of the three groups.  The order of group fulfillment
is \ord, \inter, \un. If both \ord and \inter are full, then any
connecting slaves go over to the \un group. The total number of desired
slaves for all groups is written into the resource file as the number of
needed slaves. This function can cause slaves in the \un group to move to
the groups desired.

It is valid for the \un group to contain more than the allocation for
it.  The default allocation for all groups is 0.
\end{apientry}

%%%
\begin{apientry}
{mw-deallocate-slaves \&key (\emph{amount} 0) (\emph{kind} :unordered)}
{Function}
This does not stop any slaves from processing any tasks, but it does lower
the number of slaves desired, clamped to zero, of any of the of group
\un, \inter, or \ord as specified. This relates to what is written in the
resource file by the master process.
\end{apientry}

%%%
\begin{apientry}
{mw-free-slave \emph{slave-id}}
{Function}
Move the slave specified by \emph{slave-id} into the \un \\ group
after it completes whatever tasks it may be running and adjust the
desired slave amounts for the group the slave was in. This does not
evict or otherwise stop currently allocated tasks from running on
that slave. The slave's group is only changed once all of the tasks
it is currently running are computed.  \end{apientry}

%%%
\begin{apientry}
{mw-num-runnable-tasks}
{Function}
Returns the number of runnable tasks which includes tasks that were
sent out and currently executing on slaves.
\end{apientry}

%%%
\begin{apientry}
{mw-num-unrunnable-tasks}
{Function}
Returns the number of unrunnable tasks in waiting to be consumed out
of \clmw with \func{mw-get-unrunnable-tasks}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{\phlabel{slave-algorithm-api}The Slave Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{define-mw-slave (\emph{argv}) \&body \emph{body}}
{Macro}
Defines the \sa for the application of which there may only be one.
When the \sa has finished computation, it must return an integer from 0 to 255
which will become the return code of the process. If this doesn't happen,
the return integer will be 255.

Parameter \emph{argv} will be the command line arguments passed to
the executable or to \func{mw-initialize} with the \clmw specific
arguments stripped out.

\Note If no \sa is specified in a \clmw application, then the default \sa
defined in listing~\ref{default-slave-algorithm} is used. An audit line
entry will occur stating that the \clmw default \sa is being used.

\begin{lisp}[label=default-slave-algorithm,caption=Default Slave Algorithm]
(define-mw-slave (argv)
  (mw-slave-loop-simple))
\end{lisp}

\end{apientry}

%%%
\begin{apientry}
{mw-slave-loop \&key (\emph{timeout} .05)}
{Function}
Process all pending tasks and return control to the \sa.

This function will return 6 values in this order:
\begin{description}
\item[master-disconnect]
	Did the master close the connection to the client (or under some conditions
	\clmw wanted to immediately exit due to some problem in the environment).
	T if the master cut the connection or the library wanted to exit, 
	\bool{NIL} otherwise.
\item[explicit-shutdown]
	Did the master send a shutdown command to the slave according to the
	master/slave protocol?  T if it did and \bool{NIL} if it didn't.
\item[total-results-completed]
	The number of total results which have been completely processed by the 
	slave.
\item[num-tasks]
	A number which is how many tasks are yet to be processed.
\item[num-results]
	The number of results that are currently waiting to be sent back. This is 
	affected by the master process with the command line parameter 
	\Option{mw-slave-result-group}.
\item[result-grouping]
	The number of results which must be grouped together before being sent
	back (or if there are no more tasks to compute whatever results are
	pending to go back get sent back).
\end{description}

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.  In the case of this function, it means we perform
bookkeeping work inside of the \clmw library and then return into
the \sa.  Setting this value too low will result in excessive CPU
usage by the master process.

\end{apientry}

%%%
\begin{apientry}
{mw-slave-loop-iterate \&key (\emph{timeout} .0001)}
{Function}
Process a \emph{single} pending task, inspect the network buffers for
more work to do, and return control to the \sa. This will generally
be extremely slow and hence has a short timeout. It returns the same values
as \func{mw-slave-loop} and there may or may not have been any new tasks
sent by the master in that time.

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out
due to inactivity.
\end{apientry}

%%%
\begin{apientry}
{mw-slave-loop-simple \&key (\emph{timeout} .05)}
{Function}
Process all pending tasks form the master and wait for more. Only
return when the master says to shutdown or there was a bad error and
return 0 or 255 respectively.

Parameter \emph{timeout} is a time unit in real seconds which should
be waited in the Network IO multiplexing library before timing out.
In the case of this function, it means we perform bookkeeping work
inside of the \clmw library and begin waiting again for more tasks
from the master, or a shutdown command. Setting this value too low
will result in excessive CPU usage by the slave process.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{The Task Structure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-task-sid \emph{task-structure}}
{Function}
Returns the slave-id for which the \emph{task-structure} was destined. 
If the task is \un, then \bool{NIL} is returned.
\end{apientry}

%%%
\begin{apientry}
{mw-task-tag \emph{task-structure}}
{Function}
Return the associated tag object for this \emph{task-structure}, or \bool{NIL}
if not set.
\end{apientry}

%%%
\begin{apientry}
{mw-task-packet \emph{task-structure}}
{Function}
Retrieve, as a list, the arguments specific to the algorithm for
which this \emph{task-structure} was created.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{The Result Structure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-result-algorithm \emph{result-structure}}
{Function}
Return an uppercase string which is the name of the \ta that produced this
\emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-sid \emph{result-structure}}
{Function}
Return the slave id of the slave which produced this \emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-tag \emph{result-structure}}
{Function}
Retrieve the unmodified tag associated with the original \emph{task-structure}
for this \emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-compute-time \emph{result-structure}}
{Function}
Return the length of time in seconds which represents how long it took to
compute this \emph{result-structure}.
\end{apientry}

%%%
\begin{apientry}
{mw-result-packet \emph{result-structure}}
{Function}
Retrieve the actual returned form of the \ta which produced this 
\emph{result-structure}.
\end{apientry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\apiheader{Miscellaneous API}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
\begin{apientry}
{mw-initialize (\emph{argv}\\
\indent \&key (\emph{system-argv} \emph{sb-ext:*posix-argv*}))}
{Function}
The entry point into \clmw. The parameter \emph{argv} is a list of
strings which represent the argument list to the library. Anything
not a \clmw specific argument will be passed to the \ma or the \sa
in the same order as it was on the command line.
\end{apientry}

%%%
\begin{apientry}
{mw-version-string}
{Function}
Return a string which represents the version number for this library.

\Note The format and meaning of this string may change in the future.
\end{apientry}

%%%
\begin{apientry}
{mw-zero-clamp \emph{value}}
{Function}
If the \emph{value} is less than zero, then return 0, otherwise return the
\emph{value}.
\end{apientry}

%%%
\phlabel{mw-dump-exec}
\begin{apientry}
{mw-dump-exec \&key (\emph{exec-name} "a.out")\\
\indent \emph{ignore-libs} \emph{remap-libs}}
{Function}

Produce an executable named \emph{exec-name}, which is \file{a.out}
by default, and copy any shared libraries needed by the application
into the current working directory.

Any shared libraries loaded in the lisp image which are already
an absolute path will be copied verbatim to the current working
directory. Any unqualified libraries will be transformed by an
algorithm approximating the search algorithm of \syscall{dlopen}
into absolute paths and then copied to the current working directory.
The dumped shared libraries must be shipped with the executable to
the target machine.

The parameter \emph{ignore-libs} is a list of strings where each string
is an unqualified library name. These libraries will be ignored by
\func{mw-dump-exec}. If this parameter is \bool{NIL}, the default,
then no libraries are ignored.

The parameter \emph{remap-libs} is an association list of strings
where the first string is an unqualified library name and the second
an absolute path to a library that will be copied to the current
working directory in place of what is found in the lisp image. If this
parameter is \bool{NIL}, the default, then no libraries are remapped.

This interface may change in the future.

\Limitation The dumped libraries must exist in the current working directory
	when the executable is run.
\end{apientry}

%%%
\begin{apientry}
{while \emph{test-expr} \&body \emph{body}}
{Macro}
A ubiquitous macro which implements the usual ``while'' loop control flow.
\end{apientry}

\section{Resource File}
\label{resource-file}

Each form in the \rfile is a two item list where the first item
is the attribute name as a keyword, and the second an arbitrary Lisp
form whose schema depends upon the specific attribute. They take the
form of:\\

\noindent\texttt{(keyword \textit{form})}\\

The current attributes for the \rfile in this version of \clmw are:

\begin{description}
\item[:computation-status] 
	The value is either the keyword \texttt{:in-progress} or the
	keyword \texttt{:finished}. It represents if the \ma thinks
	the computation is finished or not. If a slave reads a \rfile
	with \texttt{:computation-status} being \texttt{:finished},
	it will exit immediately with a status of zero.

\item[:timestamp] 
	The value is an integer which represents the universal time when the file
	was written.

\item[:member-id] 
	The value is a string which must match in the master and slave.

\item[:update-interval]
	The value is an integer which represents the number of seconds since the
	timestamp after which the resource file will be re-written. The default 
	is 300 seconds.

\item[:slaves-needed]
	This value represents the raw number of slaves the \ma has requested in
	order to complete its task.

\item[:slave-executable]
	This value is a list where the first element is a string
	representing the full path to the executable which is the
	slave executable, and the second element is a list of strings
	representing full paths to any shared libraries that have to
	be moved along with the executable.

\item[:slave-arguments]
	This value is a list of strings which are the command line arguments,
	in order, with which the slave is to be spawned.
\end{description}

An example file:

\begin{lisp}[caption=Contents of a sample \rfile]
;; Status of the computation
(:computation-status :in-progress)
;; Time Stamp of Resource File
(:timestamp 3488766071)
;; Member ID
(:member-id "default-member-id")
;; Update Interval (sec) of Resource File
(:update-interval 300)
;; Slaves Needed
(:slaves-needed 1000)
;; Slave Executable and Shared Libs
(:slave-executable 
   ("/home/psilord/bin/a.out" ("/home/psilord/bin/libiolib-syscalls.so")))
;; Slave Arguments
(:slave-arguments ("--mw-slave" "--mw-master-host" "black" 
                   "--mw-master-port" "47416"))
\end{lisp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendices
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\chapter{Example Application Descriptions}

\section{Hello-World}
The canonical example detailed in this manual.

\section{Ping}
The \ta for this example returns \keyword{ping-ok} if presented with
a \keyword{ping} argument, or otherwise \keyword{ping-not-ok}. The
interesting aspect of this example is the use of the \emph{general
target number} API for the in memory tasks. Billions of tasks can
be run through this application, but only a small number are kept in
memory at any give time to prevent memory exhaustion.

\section{Monte-Carlo-Pi}
This example implements the Monte Carlo algorithm to compute pi. Each
task runs N trials and returns N and the number of trials in the
circle.  The master keeps a running sum of the total trials and
the total number of trials in the circle. At the end of the maximum
number of iterations, the approximation algorithm is performed with
the computed ratio and the approximation to pi is produced.  You may
specify \OptionV{--max-trial-sets}{integer} to the master process
to state the total number of trial sets that must be performed. The
number of trials performed by each trial-set is non-configurable.

\section{Higher-Order}
This example shows that \tas can be quite versatile. Here the
\textit{horder} \ta compiles a function presented to it as an argument
and applies it to the data also presented to it returning the result
of the application. The \ma creates a unique function for each task
and associates it with the data for that task. All results are printed
out when gotten back from the slaves. While this example shows the
fundamental sketch of producing higher order \tas, more work would
be needed to handle signaled errors or other problems that could show
up in the \ta.

\section{Argument-Processing}
This example shows how to define \tas that use the optional and
available lambda list keywords. The returned result from each task
shows the values of the parameters passed to the \ta.

\chapter{\label{version-history}Version History}

% Format to use is:
% \begin{verhist}{X.Y.Z}{MM/DD/YYYY}
% or
% \begin{verhist}{0.2}{from HEAD on \today.} if in development.

\begin{verhist}{0.4}{03/24/2015}
\knownbug Until further notice, do not specify resource file names with a
	dot in them.
\bugfix Changed from the depreciated \texttt{SB-EXT:QUIT} SBCL function to
	the ASDF \texttt{UIOP:QUIT} instead.
\bugfix Hardened discovery mechanism for fixating shared libraries loaded
	into the lisp image when producing MW executables.
\end{verhist}

\begin{verhist}{0.3}{03/27/2012}
\newfeature The macro \macro{define-mw-algorithm} now generates an 
	additional macro named
	\macro{mw-with-task-policy-for-\emph{name}}. This new macro
	allows one to name a task adder function for the \ta which
	honors a specific task policy. This named function can be used
	as a regular Common Lisp function (mapped across a list, etc)
	in the body of the macro.
\end{verhist}

\begin{verhist}{0.2}{04/12/2011}
\newfeature Added basic support for the lambda list keywords of \rest,
	\optional, and \key for use by the \tas.
\newfeature Added a new example, \textit{Argument-Processing}, demonstrating 
	the use of the \rest, \optional, and \key lambda list keywords in a \ta.
\bugfix Fixed various warnings in the examples.
\bugfix Fixed broken navigation icon links in html manual.
\end{verhist}

\begin{verhist}{0.1}{11/02/2010}
\info Initial release of \clmw.
\end{verhist}

\chapter{Acknowledgements}

I would like to graciously thank: my wife Stephanie--who often put
up with me vanishing for hours on end to write and test \clmw, Greg
Thain, Mick Beaver, and Alan De Smet, whom acted as sounding boards
for the implementation and gave great feedback in the design of the
system, manual, and how a user other than me would want to interact
with it. In addition, I would like to thank the various denizens at
\texttt{comp.lang.lisp} and \texttt{\#lisp} for answering my many
questions about Lisp.

\clmw is not an official product from the Condor Project. It is written
by me in my free time. If you would like to use a C++ version of the
\mw paradigm then check out \texttt{Condor-MW} from Condor's website.

\backmatter

\end{document}



